---
title: "Rick e Morty Series"
author: "Matteo Galvan"
date: '2022-06-27'
output:
  ioslides_presentation:
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, message=F, warning=F}
library(tidytext)
library(tidyverse)
library(tidygraph)
library(subtools)
library(ggplot2)
library(dplyr)
library(wordcloud)
library(igraph)
library(ggraph)
library(widyr)
library(resolution)
library(textdata)
library(reshape2)
library(wordcloud2)
library(ggpubr)
library(plotly)
```

## Introduzione

Rick e Morty è una serie tv americana prodotta per Adult Swim arrivata alla quinta stagione e ancora in produzione. Il genere è il cosmic horror. La serie parla di Rick, nonno di Morty e padre di Beth che ritorna nella famiglia di sua figlia. Passa il suo tempo ad inventare gadget futuristici e a viaggiare in mondi e universi parlalleli prima con suo nipote Morty, e poi con sua nipote Summer.

## Caratteristiche

Per effettuare questo studio sono stati recuperati i dialoghi di ogni episodio tramite i sottotitoli in inglese. Utilizzando un pacchetto chiamato subtools questi file sono stati convertiti in un dataset utilizzabile, formato da tutte le battute della serie. Il dataset è formato da 51 episodi.

## Frequenza delle parole

Per andare a studiare la frequenza delle parole all'interno delle 5 stagioni di Rick e Morty si utilizza il pacchetto wordcloud2, per andare a creare una rappresentazione delle parole utilizzate maggiormente.

Le parole più usate sono rappresentate con un font del testo più grande, mentre quelle meno presenti sono più piccole. Inoltre se le parole sono al centro del grafico sono maggiormente importanti.
Inoltre due parole con una frequenza simile hanno uno stesso colore.


```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
options(ggrepel.max.overlaps = Inf)
dataF <- read_subtitles_season(dir = "./ddd/")
ds_noTag <- clean_tags(dataF)
ds_noCap <- clean_captions(ds_noTag)
ds_noCap <- clean_patterns(ds_noCap, "gonna")

#cerchiamo le parole
ds_singleWord <- unnest_tokens(ds_noCap, word, Text_content) %>% rename(word = "word") %>% select(Season, Episode, word) %>% anti_join(stop_words)
ds_senteces <- ds_noCap %>% rename(Sentence = "Text_content") %>% select(Season, Episode, Sentence)
```

## Frequenza delle parole
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}

#wordcloud_1 <- ds_singleWord %>% count(word) %>%
  #with(wordcloud(words = word, freq = n, min.freq = 1, max.words=100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2")))
```

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
occorrences <- ds_singleWord %>% count(word) %>% arrange(-n)

wordcloud2(occorrences, size=0.9, minSize = 0.5, color='random-light', shape = 'diamond')
```

## Frequenza delle parole
I due termini maggiormente presenti sono il nome di Rick e di Morty che sostanzialmente sono i protagonisti di ogni episodio. Inoltre in molti episodi esistono più versioni di Morty e di Rick che si nominano a vicenda e questo comporta che ci sia una maggior presenza di questi termini.

Inoltre gli altri termini molto presenti sono le esclamazioni che il nonno di Morty esclama come un intercalare.

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
ggplot(head(occorrences, 10), aes(x = reorder(word, -n), y = n)) + geom_bar(stat = "identity")
```

## Rick

Possiamo notare come per esempio nell'episodio 1x10, si dica molto la parola Rick. Infatti questo episodio nominato "Rick e Summer" parla d una festa organizzata da Rick in cui invita i suoi amici a casa sua.

Possiamo notare come per esempio nell'episodio 3x07, si dica molto la parola Rick. Infatti questo episodio nominato "A Ricklantide" è ambientato nella città dei Rick in cui sono presenti moltissime versioni dello stesso uomo ma di molti universi paralleli.

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
freq <- ds_singleWord %>% filter(word == "rick") %>%
  count(Season, Episode)

ggplot(freq)+
  geom_bar(aes(y = n, x = Episode, fill = Episode), stat = "identity", show.legend=F)+
  ylab("Numero di Occorrenze")+
  xlab("Episodi")+
  ggtitle("Occorrrenze di Rick") +
  facet_wrap(~Season, scales = 'free_x', ncol=5) +
  theme(panel.spacing = unit(0, 'lines'))
```

## Summer

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
freq <- ds_singleWord %>% filter(word == "summer") %>%
  count(Season, Episode)

ggplot(freq)+
  geom_bar(aes(y = n, x = Episode, fill = Episode), stat = "identity", show.legend=F)+
  ylab("Numero di Occorrenze")+
  xlab("Episodi")+
  ggtitle("Occorrrenze di Summer") +
  facet_wrap(~Season, scales = 'free_x', ncol=5) +
  theme(panel.spacing = unit(0, 'lines'))
```

Osservando le frequenze del nome Summer, nell'episodio 2x07, Summer chiede aiuto a suo nonno Rick per uccidere un vampiro. Rispetto ad altri episodi il nome di Summer compare di più perchè è ambientato nella scuola che lei frequenta.

## Analisi preliminare TOGLIERE?

Come varia il numero di battute di ogni episodio per ogni stagione?

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
rM_numberBattute <- ds_senteces %>%
  count(Season, index=Episode)
  
ggplot(rM_numberBattute, aes(index, n, fill = Season)) +
  facet_wrap(~Season, ncol = 2, scales = "free_x")+
  geom_line(aes(y = n), colour="blue", size=0.5, show.legend = FALSE)
```

Osservando il grafico si vede che l'andamento del numero di battute per ogni episodio è abbastanza costante. In generale si può osservare che gli ultimi episodi, in alcuni casi, contengono un numero minore di battute.


## Distribuzione dei termini NON HA SENSO

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
ggplot(occorrences, aes(x = reorder(word, -n), y = n, group = 1)) + 
  geom_line(colour="blue", size=0.5, show.legend = FALSE) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

## Densità dei termini

Quale densità e che distribuzione di frequenza assoluta possiedono i termini che compaiono nelle 5 stagioni?

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}

density <- ggplot(occorrences, aes(x=n)) + geom_density(alpha=.3, color="darkblue") +
  theme(panel.border = element_rect(colour = "black", fill=NA, size=0.5))

freqAss <- ggplot(occorrences, aes(x=word, y=n, label=word)) + 
  geom_point(aes(colour = cut(n, c(-Inf, 300, Inf))),
             size = 2, show.legend=F) +
  scale_color_manual(name = "n",
                     values = c("(-Inf,300]" = "black",
                                  "(300, Inf]" = "red")) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill=NA, size=0.5))+
  geom_text(aes(label=ifelse(n>300,as.character(word),'')),hjust=1,vjust=1.1)

ggarrange(density, freqAss,
          ncol = 2, nrow = 1)
```

Il primo grafico rappresenta con quale densità compaiono i termini e vediamo che è un'iperbole in cui pochi termini compaiono molte volte e tanti termini compaiono poco.

Nel secondo grafico verifichiamo la stessa cosa, osservando una grande quantità di punti rappresentanti le parole che hanno una frequenza assoluta molto bassa, e pochi termini, tipo il termine "Rick" e "Morty" che compaiono molto di più.


## Bigram analysis

Un bigram è una sequenza di due elementi adiacenti da una stringa di token, che in questo caso sono parole. I bigram sono utilizzabili per andare a studiare la correlazione tra termini e per verificare quali sono le parole che sono maggiormente collegate alle altre.

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bigrams <- unnest_tokens(ds_senteces, bigram, Sentence, token = "ngrams", n = 2)
bigrams <- bigrams %>% filter(!is.na(bigram)) %>% filter(bigram != "ah ah", bigram != "ha ha")

#bigrams %>% count(bigram, sort = TRUE)

bigrams_separated <- bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

#bigram_counts

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

#bigrams_united

bigram_counts2 <- bigrams_united %>% 
  count(bigram, sort = TRUE)

#bigram_counts2

```
## Bigram analysis

Quali sono i bigram maggiormente presenti?

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bigrams_for_plot = bigrams_united %>% semi_join(head(bigram_counts2, 10)) %>%
  count(bigram, Season, sort=TRUE)

xform <- list(categoryorder = "array",
              categoryarray = unique(bigrams_for_plot$chapter))

bigrams_plot <- plot_ly(bigrams_for_plot, x = ~Season, y = ~n, type = 'bar', color = ~bigram)
bigrams_plot <- bigrams_plot %>% layout(yaxis = list(title = 'number of bigrams'), barmode = 'stack', xaxis = xform)

bigrams_plot
```

## Bigram analysis

Il grafico è stato diviso per stagione e rappresenta la frequenza assoluta dei 10 bigram maggiormente presenti nei dialoghi.

Si nota che i bigram maggiormente utilizzati, oltre ai nomi quali "Rick Sanchez", "Hey Rick" e "Grandpa Rick", sono tutte esclamazioni. Infatti se si osserva la frequenza con cui queste esclamazioni compaiono si vede che nelle ultime stagione è stato fatto un uso maggiore di esclamazioni negative, rispetto a quelle innocue come "yeah yeah".

## Grafo

Rappresentazione grafica della connessione dei termini. 

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bigram_graph <- bigram_counts %>%
  filter(n > 3) %>% 
  as_tbl_graph()

a <- grid::arrow(type = "closed", length = unit(.1, "inches"))

# plot the graph
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 1) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

head(bigram_counts, 1000) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link0()+
  geom_node_point(color = "lightblue", size = 1) +
  geom_node_text(aes(label = name), vjust = 1, size=3, col = "darkgreen") +
  labs(title="Bigram Network")
```

## Frequenza bigram in base al tf-idf

I bigram possono essere visti come singoli termini e per ogni termine si può calcolare il tf-idf come misurazione per capire quanto un termine è discriminante di un testo, in questo caso delle stagioni.

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}

bigram_tf_idf <- bigrams_united %>%
  count(Season, bigram) %>%
  bind_tf_idf(bigram, Season, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  group_by(Season) %>%
  top_n(6, tf_idf) %>%
  ungroup() %>%
  mutate(bigram = reorder(bigram, tf_idf)) %>%
  ggplot(aes(bigram, tf_idf, fill = Season)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Season, ncol = 2, scales = "free") +
  coord_flip() +
  labs(y = "tf-idf of bigram to season",
       x = "")
```

## Frequenza bigram in base al tf-idf

Dal grafico, diviso per stagioni, si vede che i bigram maggiomente presenti sono quelli che discriminano maggiormente la stagione. Per esempio nella stagione 2 è presente il bigram mini Rick che compare molte volte ma in un singolo episodio e questo lo rende un termine molto importante.

Nelle altre stagione non c'è una grande rilevanza di termini.

## Correlazione Pairwise

Oltre a vedere le coppie di termini più frequenti è possibile andare a studiare le parole che possiedono maggior correlazione, perchè compaiono nella stessa situazione ma non sono per forza adiacenti.

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
word_cor <- ds_singleWord %>% filter(word != "ah", word != "ha") %>% mutate(Sigla = paste(Season, Episode)) %>%
  add_count(word, Sigla) %>%
  filter(n >= 10) %>%
  arrange(-n)

word_cor <- distinct(word_cor)
word_cor <- word_cor %>% pairwise_cor(word, Sigla, sort = TRUE)
```

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
struct <- word_cor %>%
  filter(correlation > .15) %>%
  as_tbl_graph() %>%
  ggraph(layout = "fr")

mcolor <- struct$data %>% mutate(mcolor = if_else(name %in% c("morty", "rick", "yeah", "time"), 
                                     "#cf5717", "#174ECF")) %>% select(mcolor)

struct +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(colour=mcolor$mcolor, size = 3)+
  geom_node_text(aes(label = name), repel = TRUE, colour=mcolor$mcolor)
```

## Correlazione

Il grafo rappresenta i termini come nodi e lo spessore dell'arco che li collega come relazione tra di essi. I nodi in rosso sono i termini che hanno una frequenza assoluta maggiore all'interno dei dialoghi.

Si può vedere che i 4 termini non hanno una relazione molto elevata con gli altri presenti all'interno del testo. 

## Misure di Centralità

```{r}

#VEDIAMO LE CARATTERISTICHE DI QUESTO GRAFO GIGANTE
struct <- bigram_counts %>%
  graph_from_data_frame() 
options(ggrepel.max.overlaps = Inf)


paths = distance_table(struct)$res
names(paths) = 1:length(paths)

C <- transitivity(struct, type="global")
```
Che misurazioni ha il grafo?

Numero di nodi:
```{r}
vcount(struct)
```

Distanza media tra due nodi:
```{r}
mean_distance(struct)
```

Diametro:
```{r}
diameter(struct)
```

Tabella delle distanze:
```{r}
paths
```

Centralità:
```{r}
C
```
## Misure di Centralità

Quale è la distribuzione della distanza media tra due nodi qualsiasi?

```{r}
barplot(paths / sum(paths), xlab="Distance", ylab="Frequency")
```

Si può notare che seppur la grandezza della rete sia abbastanza elevata (7109 nodi), in realtà la distanza media tra due nodi qualsiasi è molto contenuta. 

Il diametro, cioè la geodesica più lunga è di 19 passi.
La centralità di vicinanza ha un valore molto basso, che è dovuto principalmente ai nodi che compaiono singolarmente, magari all'interno di una singola battuta effettuata da un personaggio.

## è connessa?

Nel grafo è presente una componente gigante?

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
# color in red the nodes in the giant component
c = components(struct)
nodes = which(c$membership == which.max(c$csize))

V(struct)$color = "white"
V(struct)[nodes]$color = "black"
plot(struct, vertex.size = 3, vertex.label=NA, edge.arrow.size=0.005, edge.arrow.width=0.0000001)

```

Il grafo mostra la componente gigante formata dai bigram collegati tra di essi.
Esiste quindi una componente gigante che prende la maggior parte di nodi. Il numero di nodi connessi è: 
```{r}
vcount(struct)-c$no
```

## Betweenness centrality

Quali sono le parole che hanno un valore di correlazione maggiore se comparate a tutte le altre parole?

Calcoliamo la centralità betweenness che va a controllare quanto una parola compara in mezzo ad altre. In sostanza va a verificare se il termine appare sulla maggior parte delle geodesiche presenti tra due termini.

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
word_cor_g <- word_cor %>%
  rename(word1 = item1, word2 = item2, n = correlation) %>%
  filter(n > 0.18)

#Betweenness centrality
g <- word_cor_g %>%
  as_tbl_graph()

v <- as_tibble(g) %>%
  mutate(v = row_number())

b <- betweenness(g)

names(b) = 1:vcount(g)

betweenness <- data.frame(score = round(b, 2)) %>%
  mutate(v = row_number()) %>%
  full_join(v) %>%
  arrange(desc(score)) %>%
  mutate(word = name) %>%
  select(word, score) %>% 
  head(10)

betweenness

#PageRank centrality
#pr <- page_rank(g)
#pagerank <- data.frame(score = pr$vector) %>%
 # arrange(desc(score)) %>%
 # head(10)

#pagerank
```
Osservando la tabella dei 10 valori con un grado più elevato, si può notare che alcuni sono nomi, ma altri in realtà sono esclamazioni.

## Community detection

Il community detection permette di trovare le divisioni naturali di una rete in un gruppo di vertici connessi, chiamate comunità. Tra queste comunità ci sono pochi archi, mentre ce ne sono un numero maggiore all'interno della comunità.

Osserviamo i termini che secondo la centralità sono maggiormente importanti:

* uh
* shit
* jerry
* god

## Community detection

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
word_cor <- ds_singleWord %>% filter(word != "ah", word != "ha") %>% mutate(Sigla = paste(Season, Episode)) %>%
  add_count(word, Sigla) %>%
  filter(n >= 15) %>%
  arrange(-n)

word_cor <- distinct(word_cor)
word_cor <- word_cor %>% pairwise_cor(word, Sigla, sort = TRUE)
word_cor_g <- word_cor %>%
  rename(word1 = item1, word2 = item2, n = correlation) %>%
  filter(n > 0.1)

g <- word_cor_g %>% 
  filter(word1 == "uh" | word2 == "uh" | word1 == "shit" | word2 == "shit" | word1 == "jerry" | word2 == "jerry"| word1 == "god" | word2 == "god")

G = graph_from_data_frame(g)
community = cluster_resolution(G, t = 1) # The number of communities typically decreases as the resolution parameter (t) grows.
coords = layout_with_fr(G) 

plot(G, vertex.color = membership(community), vertex.size = 10, layout = coords, edge.arrow.size = 0.05, edge.arrow.width=0.00001, layout=layout_with_kk(G), vertex.label.dist=1)

```

Possiamo notare che???????????

##Sentiment Analisy
Cosa è

## Wordcloud positive and negative


```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bing <- get_sentiments("bing")

ds_singleWord %>% 
  inner_join(bing, "word") %>%
  count(word, sentiment, sort=T) %>% 
  acast(word ~ sentiment, value.var = "n", fill=0) %>% 
  comparison.cloud(colors=c("#991D1D", "#327CDE"), max.words = 100)
```

## Comparison di numeri
Usato Bing
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
nrc <- get_sentiments("nrc")
sentiments <- ds_singleWord %>% 
  inner_join(nrc, "word") %>%
  count(sentiment, sort=T)

sentiments %>% 
  ggplot(aes(x=reorder(sentiment, n), y=n)) +
  geom_bar(stat="identity", aes(fill=sentiment), show.legend=F) +
  geom_label(label=sentiments$n) +
  labs(x="Sentiment", y="Frequency", title="How is the overall mood in Rick&Morty?") +
  coord_flip()
```

## Sentimenti divisi tramite NRC
Cosa è come funziona
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
ds_singleWord %>% 
  inner_join(nrc, "word") %>% 
  count(sentiment, word, sort=T) %>% 
  group_by(sentiment) %>% 
  arrange(desc(n)) %>% 
  slice(1:7) %>% 
  ggplot(aes(x=reorder(word, n), y=n)) +
  geom_col(aes(fill=sentiment), show.legend = F) +
  facet_wrap(~sentiment, scales = "free_y") +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  coord_flip() +
  theme_bw() +
  labs(x="Word", y="Frequency", title="Sentiment split by most frequent words")
```

## Le parole che influenzano maggiormente il tutto, tramite nrc
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
afinn <- get_sentiments("afinn")

ds_singleWord %>% 
  # by word and value count number of occurences
  inner_join(afinn, "word") %>% 
  count(word, value, sort=T) %>% 
  mutate(contribution = n * value,
         sentiment = ifelse(contribution<=0, "Negative", "Positive")) %>% 
  arrange(desc(abs(contribution))) %>% 
  head(20) %>% 
  
  ggplot(aes(x=reorder(word, contribution), y=contribution, fill=sentiment)) +
  geom_col(aes(fill=sentiment), show.legend = F) +
  labs(x="Word", y="Contribution", title="Words with biggest contributions in positive/negative moods") +
  coord_flip() +
  scale_fill_manual(values=c("#FA8072", "#08439A")) + 
  theme_bw()
```

## per stagione

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
rick_morty_sentiment2 <- ds_singleWord %>%
  inner_join(get_sentiments("bing")) %>%
  count(Season, index=Episode, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

df2 <- melt(rick_morty_sentiment2 %>% 
              mutate(Negative = -negative) %>% 
              select(Season, positive, Negative), 
            id.vars='Season')

ggplot(df2, aes(x=variable, y=value, fill=factor(Season))) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_discrete(name="Season",
                      breaks=c(1, 2, 3, 4, 5),
                      labels=c("1", "2", "3", "4", "5"))+
  xlab("Sentiment")+ylab("Count")
```

## per episodio

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
ggplot(rick_morty_sentiment2, aes(index, sentiment, fill = Season)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Season, ncol = 2, scales = "free_x")
```





## resoconto per episodi del 1° stagione

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
df2 <- melt(rick_morty_sentiment2 %>% 
              mutate(Negative = -negative) %>% 
              select(index, positive, Negative), 
            id.vars='index')

ggplot(df2, aes(x=variable, y=value, fill=factor(index))) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_discrete(name="Season",
                      breaks=c(1, 2, 3, 4, 5),
                      labels=c("1", "2", "3", "4", "5"))+
  xlab("Sentiment")+ylab("Count")

```

## Pos di tutti gli episodi

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
a <- rick_morty_sentiment2
ggplot(rick_morty_sentiment2 %>% mutate(Sigla = paste(a$Season, a$index)),
       aes(x=Sigla, index, y=positive, fill=factor(index))) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_discrete(name="Season",
                      breaks=c(1, 2, 3, 4, 5),
                      labels=c("1", "2", "3", "4", "5"))+
  xlab("Sentiment")+ylab("Count") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```



## Neg di tutti gli episodi
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
a <- rick_morty_sentiment2
ggplot(rick_morty_sentiment2 %>% mutate(Sigla = paste(a$Season, a$index)),
       aes(x=Sigla, index, y=-negative, fill=factor(index))) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_discrete(name="Season",
                      breaks=c(1, 2, 3, 4, 5),
                      labels=c("1", "2", "3", "4", "5"))+
  xlab("Sentiment")+ylab("Count") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

## Conclusione
Possiamo concludere che
