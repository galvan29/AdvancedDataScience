---
title: "Rick e Morty Series"
author: "Matteo Galvan"
date: '2022-06-27'
output:
  ioslides_presentation:
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, message=F, warning=F}
library(tidytext)
library(tidyverse)
library(tidygraph)
library(subtools)
library(ggplot2)
library(dplyr)
library(wordcloud)
library(igraph)
library(ggraph)
library(widyr)
library(resolution)
library(textdata)
library(reshape2)
library(wordcloud2)
```

## Introduzione

Rick e Morty è una serie tv americana prodotta per Adult Swim arrivata alla quinta stagione e ancora in produzione. Il genere è il cosmic horror. La serie parla di Rick, nonno di Morty e padre di Beth che ritorna nella famiglia di sua figlia. Passa il suo tempo ad inventare gadget futuristici e a viaggiare in mondi e universi parlalleli prima con suo nipote Morty, e poi con sua nipote Summer.

## Caratteristiche

Per effettuare questo studio sono stati recuperati i dialoghi di ogni episodio tramite i sottotitoli in inglese. Utilizzando un pacchetto chiamato subtools questi file sono stati convertiti in un dataset utilizzabile, formato da tutte le battute della serie. 

## Frequenza delle parole

Per andare a studiare la frequenza delle parole all'interno delle 5 stagioni di Rick e Morty si utilizza il pacchetto wordcloud2, per andare a creare una rappresentazione delle parole utilizzate maggiormente.

Le parole più usate sono rappresentate con un font del testo più grande, mentre quelle meno presenti sono più piccole. Inoltre se le parole sono al centro del grafico sono maggiormente importanti.
Inoltre due parole con una frequenza simile hanno uno stesso colore.


```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
options(ggrepel.max.overlaps = Inf)
dataF <- read_subtitles_season(dir = "./ddd/")
ds_noTag <- clean_tags(dataF)
ds_noCap <- clean_captions(ds_noTag)
ds_noCap <- clean_patterns(ds_noCap, "gonna")

#cerchiamo le parole
ds_singleWord <- unnest_tokens(ds_noCap, word, Text_content) %>% rename(word = "word") %>% select(Season, Episode, word) %>% anti_join(stop_words)
ds_senteces <- ds_noCap %>% rename(Sentence = "Text_content") %>% select(Season, Episode, Sentence)
```

## Frequenza delle parole
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}

#wordcloud_1 <- ds_singleWord %>% count(word) %>%
  #with(wordcloud(words = word, freq = n, min.freq = 1, max.words=100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2")))
```

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
occorrences <- ds_singleWord %>% count(word) %>% arrange(-n)

wordcloud2(occorrences, size=0.9, minSize = 0.5, color='random-light', shape = 'diamond')
```

## Frequenza delle parole
I due termini maggiormente presenti sono il nome di Rick e di Morty che sostanzialmente sono i protagonisti di ogni episodio. Inoltre in molti episodi esistono più versioni di Morty e di Rick che si nominano a vicenda e questo comporta che ci sia una maggior presenza di questi termini.

Inoltre gli altri termini molto presenti sono le esclamazioni che il nonno di Morty esclama come un intercalare.

## Rick

Possiamo notare come per esempio nell'episodio 1x10, si dica molto la parola Rick. Infatti questo episodio nominato "Rick e Summer" parla d una festa organizzata da Rick in cui invita i suoi amici a casa sua.

Possiamo notare come per esempio nell'episodio 3x07, si dica molto la parola Rick. Infatti questo episodio nominato "A Ricklantide" è ambientato nella città dei Rick in cui sono presenti moltissime versioni dello stesso uomo ma di molti universi paralleli.

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
freq <- ds_singleWord %>% filter(word == "rick") %>%
  count(Season, Episode)

ggplot(freq)+
  geom_bar(aes(y = n, x = Episode, fill = Episode), stat = "identity", show.legend=F)+
  ylab("Numero di Occorrenze")+
  xlab("Episodi")+
  ggtitle("Occorrrenze di Rick") +
  facet_wrap(~Season, scales = 'free_x', ncol=5) +
  theme(panel.spacing = unit(0, 'lines'))
```

## Summer

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
freq <- ds_singleWord %>% filter(word == "summer") %>%
  count(Season, Episode)

ggplot(freq)+
  geom_bar(aes(y = n, x = Episode, fill = Episode), stat = "identity", show.legend=F)+
  ylab("Numero di Occorrenze")+
  xlab("Episodi")+
  ggtitle("Occorrrenze di Summer") +
  facet_wrap(~Season, scales = 'free_x', ncol=5) +
  theme(panel.spacing = unit(0, 'lines'))
```

Nell'episodio 2x07, Summer chiede aiuto a suo nonno Rick per uccidere un vampiro. Rispetto ad altri episodi il nome di Summer compare di più perchè è ambientato nella scuola che lei frequenta.

## Analisi preliminare 

Come varia il numero di battute di ogni episodio per ogni stagione?

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
rM_numberBattute <- ds_senteces %>%
  count(Season, index=Episode)
  
ggplot(rM_numberBattute, aes(index, n, fill = Season)) +
  facet_wrap(~Season, ncol = 2, scales = "free_x")+
  geom_line(aes(y = n), colour="blue", size=0.5, show.legend = FALSE)
```

Osservando il grafico si vede che l'andamento del numero di battute per ogni episodio è abbastanza costante. In generale si può osservare che gli ultimi episodi, in alcuni casi, contengono un numero minore di battute.




## Distribuzione dei termini negli episodi

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
ggplot(occorrences, aes(x = reorder(word, -n), y = n, group = 1)) + 
  geom_line(colour="blue", size=0.5, show.legend = FALSE) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```



## Densità dei termini

Densità dei termini, devo rimuovere i termini sull'asse delle x


```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}

ggplot(occorrences, aes(x=n)) + geom_density(alpha=.3)

ggplot(occorrences, aes(x=word, y=n)) + 
  geom_point()

parole <- ds_singleWord %>% semi_join(head(occorrences, 10))

ggplot(head(occorrences, 10), aes(x = reorder(word, -n), y = n)) + geom_bar(stat = "identity")

```


## Bigram analysis

Cosa è sta analisi? Spieghiamo


## Bigram analysis

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bigrams <- unnest_tokens(ds_senteces, bigram, Sentence, token = "ngrams", n = 2)
bigrams <- bigrams %>% filter(!is.na(bigram))

#bigrams %>% count(bigram, sort = TRUE)

bigrams_separated <- bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

#bigram_counts

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

#bigrams_united

bigram_counts2 <- bigrams_united %>% 
  count(bigram, sort = TRUE)

#bigram_counts2

```
## Bigram analysis

Spieghiamo delle analisi possibili sui bigrams

Grafico che NON HO FATTO CODDUE SULLE COPPIE più presenti


## TF-IDF 
Spieghiamo a che serve e mostriamo i maggiori presenti per argomento

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bigram_tf_idf <- bigrams_united %>%
  count(Season, bigram) %>%
  bind_tf_idf(bigram, Season, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf

bigram_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  group_by(Season) %>%
  top_n(6, tf_idf) %>%
  ungroup() %>%
  mutate(bigram = reorder(bigram, tf_idf)) %>%
  ggplot(aes(bigram, tf_idf, fill = Season)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Season, ncol = 2, scales = "free") +
  coord_flip() +
  labs(y = "tf-idf of bigram to season",
       x = "")
```

## Grafo delle coppie di parole collegate
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
arrows <- grid::arrow(type="closed", length=unit(0.15, "inches"))
ggraph(head(bigram_counts, 1000), layout="fr") +
  geom_edge_link(aes(edge_alpha=n), show.legend = F, arrow=arrows, end_cap=circle(0.03,'inches')) +
  geom_edge_density(aes(fill = n)) +
  geom_node_point(color="black", size=2) +
  geom_node_text(aes(label=name), repel=T) +
  labs(title="Bigram Network")
```

Ma sono uguali?

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
head(bigram_counts, 1000) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link0()+
  geom_node_point(color = "lightblue", size = 1) +
  geom_node_text(aes(label = name), vjust = 1, size=3, col = "darkgreen") +
  labs(title="Bigram Network")
```

## Correlazione - non va 
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
word_pairs <- ds_singleWord %>% filter(Season == 1) %>% 
  pairwise_count(word, Episode, sort = TRUE)

word_cors <- ds_singleWord %>% #filter(Season == 1) %>% 
  group_by(word) %>%
  filter(n() >= 50) %>%
  pairwise_cor(word, Episode, sort = TRUE)

struct <- word_cors %>%
  filter(correlation > .25) %>%
  as_tbl_graph() 


struct %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = "lightblue", size = 1) +
  geom_node_text(aes(label = name), repel = TRUE)
```
#correlazione con anche indice di quanto sono uguali, se cambio 
#il filter cambia tutto
Spiegazione di questo

## Misure Varie della stagione 1

```{r}
#misure di centralità
word_cors <- ds_singleWord %>% filter(Season == 1) %>% 
  group_by(word) %>%
  pairwise_cor(word, Episode, sort = TRUE)

#VEDIAMO LE CARATTERISTICHE DI QUESTO GRAFO GIGANTE
struct <- bigram_counts %>%
  graph_from_data_frame() 
options(ggrepel.max.overlaps = Inf)
vcount(struct)
mean_distance(struct)
diameter(struct)
distance_table(struct)

paths = distance_table(struct)$res
names(paths) = 1:length(paths)
barplot(paths / sum(paths), xlab="Distance", ylab="Frequency")

paths
C <- transitivity(struct, type="global")
C
```
VEDIAMO DA PRIMA CHE IL CAMMINO MINIMO TRA DUE NODI è BASSO, sta a 5, diametro max 19
Una rete presenta un comportamento di tipo small world se e solo se L
cresce in modo logaritmico (o inferiore) in funzione di n, dove n è il
numero di nodi della rete. Il grado dei nodi del grafo ha un valore medio
prefissato


è una rete abbastanza grande (7106 nodi) con dei cammini minimi medi di tot ma la centralità di vicinanza non è alta, anzi è bassa, perchè ci sono moltissime parole che non sono associate ad altre. 

## è connessa?
No, componente gigante
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
# color in red the nodes in the giant component
c = components(struct)
nodes = which(c$membership == which.max(c$csize))

V(struct)$color = "white"
V(struct)[nodes]$color = "black"
plot(struct, vertex.size = 3, vertex.label=NA, edge.arrow.size=0.005, edge.arrow.width=0.0000001)

```


## SCC
Non va porcoddue
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
#COMPONENTE FORTEMNTE CONNESSA
c = components(struct, mode="strong")
nodes = which(c$membership == which.max(c$csize))
coords = layout_with_fr(struct)
# color in red the nodes in the giant component
V(struct)$color = "white"
V(struct)[nodes]$color = "black"
plot(struct, layout=coords, 
     vertex.size = 6, vertex.label=NA, 
     edge.arrow.size = 0.5, edge.arrow.width=0.001)
```

## Betweenness centrality
Betweennees e PageRank

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
word_cor_g <- word_cors %>%
  rename(word1 = item1, word2 = item2, n = correlation) %>%
  mutate(n = round(n*100)) %>%
  filter(n > 18)

#Betweenness centrality
g <- word_cor_g %>%
  as_tbl_graph()

v <- as_tibble(g) %>%
  mutate(v = row_number())

b <- betweenness(g)

names(b) = 1:vcount(g)

betweenness <- data.frame(score = round(b, 2)) %>%
  mutate(v = row_number()) %>%
  full_join(v) %>%
  arrange(desc(score)) %>%
  mutate(word = name) %>%
  select(word, score) %>% 
  head(10)

betweenness

#PageRank centrality
pr <- page_rank(g)
pagerank <- data.frame(score = pr$vector) %>%
  arrange(desc(score)) %>%
  head(10)

pagerank
```

##Community detection
Per ora fa solo della prima stagione. Possiamo rimuovere i verbi
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
word_cors <- ds_singleWord %>% filter(Season == 1) %>% 
  group_by(word) %>%
  filter(n() >= 10) %>%
  pairwise_cor(word, Episode, sort = TRUE)

word_cor_g <- word_cors %>%
  rename(word1 = item1, word2 = item2, n = correlation) %>%
  mutate(n = round(n*100)) %>%
  filter(n > 40)

g <- word_cor_g %>% 
  filter((word1 == "watch" | word2 == "watch" | word1 == "fun" | word2 == "fun" | word1 == "damn" | word2 == "damn"| word1 == "smith" | word2 == "smith") & !grepl('’', word1) & !grepl('’', word2) )

G = graph_from_data_frame(g)
community = cluster_resolution(G, t = 1) # The number of communities typically decreases as the resolution parameter (t) grows.
coords = layout_with_fr(G) 

plot(G, vertex.color = membership(community), layout = coords, edge.arrow.size = 0.5, edge.arrow.width=0.001)

```
##Sentiment Analisy
Cosa è

## Wordcloud positive and negative


```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bing <- get_sentiments("bing")

ds_singleWord %>% 
  inner_join(bing, "word") %>%
  count(word, sentiment, sort=T) %>% 
  acast(word ~ sentiment, value.var = "n", fill=0) %>% 
  comparison.cloud(colors=c("#991D1D", "#327CDE"), max.words = 100)
```

## Comparison di numeri
Usato Bing
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
nrc <- get_sentiments("nrc")
sentiments <- ds_singleWord %>% 
  inner_join(nrc, "word") %>%
  count(sentiment, sort=T)

sentiments %>% 
  ggplot(aes(x=reorder(sentiment, n), y=n)) +
  geom_bar(stat="identity", aes(fill=sentiment), show.legend=F) +
  geom_label(label=sentiments$n) +
  labs(x="Sentiment", y="Frequency", title="How is the overall mood in Rick&Morty?") +
  coord_flip()
```

## Sentimenti divisi tramite NRC
Cosa è come funziona
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
ds_singleWord %>% 
  inner_join(nrc, "word") %>% 
  count(sentiment, word, sort=T) %>% 
  group_by(sentiment) %>% 
  arrange(desc(n)) %>% 
  slice(1:7) %>% 
  ggplot(aes(x=reorder(word, n), y=n)) +
  geom_col(aes(fill=sentiment), show.legend = F) +
  facet_wrap(~sentiment, scales = "free_y") +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  coord_flip() +
  theme_bw() +
  labs(x="Word", y="Frequency", title="Sentiment split by most frequent words")
```

## Le parole che influenzano maggiormente il tutto, tramite nrc
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
afinn <- get_sentiments("afinn")

ds_singleWord %>% 
  # by word and value count number of occurences
  inner_join(afinn, "word") %>% 
  count(word, value, sort=T) %>% 
  mutate(contribution = n * value,
         sentiment = ifelse(contribution<=0, "Negative", "Positive")) %>% 
  arrange(desc(abs(contribution))) %>% 
  head(20) %>% 
  
  ggplot(aes(x=reorder(word, contribution), y=contribution, fill=sentiment)) +
  geom_col(aes(fill=sentiment), show.legend = F) +
  labs(x="Word", y="Contribution", title="Words with biggest contributions in positive/negative moods") +
  coord_flip() +
  scale_fill_manual(values=c("#FA8072", "#08439A")) + 
  theme_bw()
```

## per stagione

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
rick_morty_sentiment2 <- ds_singleWord %>%
  inner_join(get_sentiments("bing")) %>%
  count(Season, index=Episode, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

df2 <- melt(rick_morty_sentiment2 %>% 
              mutate(Negative = -negative) %>% 
              select(Season, positive, Negative), 
            id.vars='Season')

ggplot(df2, aes(x=variable, y=value, fill=factor(Season))) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_discrete(name="Season",
                      breaks=c(1, 2, 3, 4, 5),
                      labels=c("1", "2", "3", "4", "5"))+
  xlab("Sentiment")+ylab("Count")
```

## per episodio

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
ggplot(rick_morty_sentiment2, aes(index, sentiment, fill = Season)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Season, ncol = 2, scales = "free_x")
```





## resoconto per episodi del 1° stagione

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
df2 <- melt(rick_morty_sentiment2 %>% 
              mutate(Negative = -negative) %>% 
              select(index, positive, Negative), 
            id.vars='index')

ggplot(df2, aes(x=variable, y=value, fill=factor(index))) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_discrete(name="Season",
                      breaks=c(1, 2, 3, 4, 5),
                      labels=c("1", "2", "3", "4", "5"))+
  xlab("Sentiment")+ylab("Count")

```

## Pos di tutti gli episodi

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
a <- rick_morty_sentiment2
ggplot(rick_morty_sentiment2 %>% mutate(Sigla = paste(a$Season, a$index)),
       aes(x=Sigla, index, y=positive, fill=factor(index))) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_discrete(name="Season",
                      breaks=c(1, 2, 3, 4, 5),
                      labels=c("1", "2", "3", "4", "5"))+
  xlab("Sentiment")+ylab("Count") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```



## Neg di tutti gli episodi
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
a <- rick_morty_sentiment2
ggplot(rick_morty_sentiment2 %>% mutate(Sigla = paste(a$Season, a$index)),
       aes(x=Sigla, index, y=-negative, fill=factor(index))) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_discrete(name="Season",
                      breaks=c(1, 2, 3, 4, 5),
                      labels=c("1", "2", "3", "4", "5"))+
  xlab("Sentiment")+ylab("Count") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

## Conclusione
Possiamo concludere che
