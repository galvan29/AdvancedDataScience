---
title: "Rick e Morty Series"
author: "Matteo Galvan"
date: '2022-06-27'
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, message=F, warning=F}
library(tidytext)
library(tidyverse)
library(tidygraph)
library(subtools)
library(ggplot2)
library(dplyr)
library(wordcloud)
library(igraph)
library(ggraph)
library(widyr)
library(resolution)
library(textdata)
library(reshape2)
library(wordcloud2)
```

## Introduzione

Qua parliamo dell'idea generale

## Rick e Morty

Spiego cosa è la serie, argomento, numero stagioni ed episodi. Dataset in inglese

## Frequenza delle parole

Posso utilizzare il wordcloud

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
options(ggrepel.max.overlaps = Inf)
dataF <- read_subtitles_season(dir = "C:/flutter_pro/AdvancedDataScience/ddd/")
ds_noTag <- clean_tags(dataF)
ds_noCap <- clean_captions(ds_noTag)
ds_noCap <- clean_patterns(ds_noCap, "gonna")

#cerchiamo le parole
ds_singleWord <- unnest_tokens(ds_noCap, word, Text_content) %>% rename(word = "word") %>% select(Season, Episode, word) %>% anti_join(stop_words)
ds_senteces <- ds_noCap %>% rename(Sentence = "Text_content") %>% select(Season, Episode, Sentence)
```

## Frequenza delle parole
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}

wordcloud_1 <- ds_singleWord %>% count(word) %>%
  with(wordcloud(words = word, freq = n, min.freq = 1, max.words=100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2")))
```

Spiegazione del primo

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
occorrences <- ds_singleWord %>% count(word) %>% arrange(-n)

wordcloud2(occorrences, size=0.9, minSize = 0.5, color='random-light', backgroundColor="black", shape="diamond", fontFamily="HersheySymbol")
```
Spiegazione del secondo

## Analisi preliminare 

Numero di battute per episodio di ogni stagione

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
rM_numberBattute <- ds_senteces %>%
  count(Season, index=Episode)
  
ggplot(rM_numberBattute, aes(index, n, fill = Season)) +
  facet_wrap(~Season, ncol = 2, scales = "free_x")+
  geom_line(aes(y = n), colour="blue", size=0.5, show.legend = FALSE)
```
Seguono tutti la stessa struttura




## Distribuzione dei termini negli episodi

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
ggplot(occorrences, aes(x = reorder(word, -n), y = n, group = 1)) + 
  geom_line(colour="blue", size=0.5, show.legend = FALSE) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```



## Densità dei termini

Densità dei termini, devo rimuovere i termini sull'asse delle x


```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}

ggplot(occorrences, aes(x=n)) + geom_density(alpha=.3)

ggplot(occorrences, aes(x=word, y=n)) + 
  geom_point()

parole <- ds_singleWord %>% semi_join(head(occorrences, 10))

ggplot(head(occorrences, 10), aes(x = reorder(word, -n), y = n)) + geom_bar(stat = "identity")

```


## Bigram analysis

Cosa è sta analisi? Spieghiamo


## Bigram analysis

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bigrams <- unnest_tokens(ds_senteces, bigram, Sentence, token = "ngrams", n = 2)
bigrams <- bigrams %>% filter(!is.na(bigram))

#bigrams %>% count(bigram, sort = TRUE)

bigrams_separated <- bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

#bigram_counts

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

#bigrams_united

bigram_counts2 <- bigrams_united %>% 
  count(bigram, sort = TRUE)

#bigram_counts2

```
## Bigram analysis

Spieghiamo delle analisi possibili sui bigrams

Grafico che NON HO FATTO CODDUE SULLE COPPIE più presenti


## TF-IDF 
Spieghiamo a che serve e mostriamo i maggiori presenti per argomento

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
bigram_tf_idf <- bigrams_united %>%
  count(Season, bigram) %>%
  bind_tf_idf(bigram, Season, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf

bigram_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  group_by(Season) %>%
  top_n(6, tf_idf) %>%
  ungroup() %>%
  mutate(bigram = reorder(bigram, tf_idf)) %>%
  ggplot(aes(bigram, tf_idf, fill = Season)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Season, ncol = 2, scales = "free") +
  coord_flip() +
  labs(y = "tf-idf of bigram to season",
       x = "")
```

## Grafo delle coppie di parole collegate
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
arrows <- grid::arrow(type="closed", length=unit(0.15, "inches"))
ggraph(head(bigram_counts, 1000), layout="fr") +
  geom_edge_link(aes(edge_alpha=n), show.legend = F, arrow=arrows, end_cap=circle(0.03,'inches')) +
  geom_edge_density(aes(fill = n)) +
  geom_node_point(color="black", size=2) +
  geom_node_text(aes(label=name), repel=T) +
  labs(title="Bigram Network")
```

Ma sono uguali?

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
head(bigram_counts, 1000) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link0()+
  geom_node_point(color = "lightblue", size = 1) +
  geom_node_text(aes(label = name), vjust = 1, size=3, col = "darkgreen") +
  labs(title="Bigram Network")
```

## Correlazione
```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
word_pairs <- ds_singleWord %>% filter(Season == 1) %>% 
  pairwise_count(word, Episode, sort = TRUE)

word_cors <- ds_singleWord %>% #filter(Season == 1) %>% 
  group_by(word) %>%
  filter(n() >= 10) %>%
  pairwise_cor(word, Episode, sort = TRUE)

struct <- word_cors %>%
  #filter(correlation > .25) %>%
  as_tbl_graph() 


struct %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = "lightblue", size = 1) +
  geom_node_text(aes(label = name), repel = TRUE)
```
#correlazione con anche indice di quanto sono uguali, se cambio 
#il filter cambia tutto
Spiegazione di questo

## Misure Varie

```{r , echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
#misure di centralità
word_cors <- ds_singleWord %>% filter(Season == 1) %>% 
  group_by(word) %>%
  pairwise_cor(word, Episode, sort = TRUE)

#VEDIAMO LE CARATTERISTICHE DI QUESTO GRAFO GIGANTE
struct <- bigram_counts %>%
  graph_from_data_frame() 
options(ggrepel.max.overlaps = Inf)
vcount(struct)
mean_distance(struct)
diameter(struct)
distance_table(struct)

paths = distance_table(struct)$res
names(paths) = 1:length(paths)
barplot(paths / sum(paths), xlab="Distance", ylab="Frequency")

paths
C <- transitivity(struct, type="global")
C
```
VEDIAMO DA PRIMA CHE IL CAMMINO MINIMO TRA DUE NODI è BASSO, sta a 5, diametro max 19
Una rete presenta un comportamento di tipo small world se e solo se L
cresce in modo logaritmico (o inferiore) in funzione di n, dove n è il
numero di nodi della rete. Il grado dei nodi del grafo ha un valore medio
prefissato


è una rete abbastanza grande (7106 nodi) con dei cammini minimi medi di tot ma la centralità di vicinanza non è alta, anzi è bassa, perchè ci sono moltissime parole che non sono associate ad altre. 

## 





